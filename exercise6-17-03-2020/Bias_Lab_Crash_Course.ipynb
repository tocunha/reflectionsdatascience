{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpYhUfZvgdGd"
   },
   "source": [
    "In this lab, we'll build a fairly simple AI classifier to find out if adopting a cat or a dog will make me happier. This is a pretty subjective question, so instead of using a dataset from the internet, we'll collect our own and use it to train a neural network to predict happiness.\n",
    "\n",
    "Here's what we need to do:\n",
    "\n",
    "*   Step 1: Decide on a few features about cats and dogs, and then conduct a survey to collect data about those features and whether they're linked to owner happiness\n",
    "*   Step 2: Build an AI model to predict if a specific pet makes people happy. Because we're not collecting a massive amount of data, we'll plan on using a neural network with one hidden layer. \n",
    "*   Step 3: Go through an adoption website, input their features into our AI, and let it decide which pet will make me happy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-rkCNpH_C8wF"
   },
   "source": [
    "# Step 1. Input survey results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfxAD9XY53Re"
   },
   "source": [
    "Instead of importing a dataset, we created our own! We chose 4 common features of dogs and cats: cuddly, soft, quiet, and energetic. And as our label, we want to know whether people are happy with their pets. \n",
    "\n",
    "For the data collection part of this process, we gave this five-question survey of yes/no questions to 30 people who own one cat or one dog. \n",
    "\n",
    "Then, we need to convert these results into features and labels. So we can put everyone’s answers into one big list, where every row is one person’s survey response. Yes is represented as 1 and No is represented as 0.\n",
    "\n",
    "We also have to split this dataset into the training set and the testing set. The training set is used to train the neural network, and the testing set is kept hidden from the neural network during training, so we can use it to check the network’s accuracy later.\n",
    "\n",
    "**Step 1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SehUtVTQQup_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Column names:  Energetic, Cuddly, Soft, Quiet, Happiness\n",
    "survey = np.array([\n",
    "  [1, 0, 1, 1, 1],  #     Energetic, Not Cuddly, Soft, Quiet,     Happy\n",
    "  [1, 1, 1, 1, 1],  #     Energetic,     Cuddly, Soft, Quiet,     Happy\n",
    "  [1, 0, 1, 0, 1],  #     Energetic, Not Cuddly, Soft, Loud,      Happy\n",
    "  [0, 0, 1, 0, 0],  # Not Energetic, Not Cuddly, Soft, Loud,  Not happy\n",
    "  [0, 1, 0, 1, 0],  # ...\n",
    "  [0, 0, 0, 1, 0],\n",
    "  [1, 1, 0, 0, 1],\n",
    "  [0, 1, 0, 0, 0],\n",
    "  [0, 1, 0, 1, 0],\n",
    "  [0, 1, 0, 0, 0],\n",
    "  [1, 0, 1, 1, 1],\n",
    "  [0, 1, 1, 1, 0],\n",
    "  [1, 0, 1, 0, 1],\n",
    "  [0, 0, 1, 0, 0],\n",
    "  [0, 1, 0, 1, 0],\n",
    "  [0, 0, 0, 1, 0],\n",
    "  [1, 1, 0, 0, 1],\n",
    "  [0, 0, 0, 0, 0],\n",
    "  [1, 0, 1, 1, 1],\n",
    "  [1, 1, 1, 1, 0],\n",
    "  [1, 0, 1, 0, 1],\n",
    "  [1, 1, 1, 0, 1],\n",
    "  [0, 0, 0, 0, 1],\n",
    "  [0, 0, 0, 1, 1],\n",
    "  [0, 0, 1, 1, 1],\n",
    "  [0, 1, 1, 1, 1]\n",
    "])\n",
    "# CHANGEME -- You can put in your own survey results as well.\n",
    "\n",
    "# First four columns are our features\n",
    "features_train = survey[:,0:4]\n",
    "# Last column is our label\n",
    "labels_train = survey[:,4]\n",
    "\n",
    "# Keeping four surveys as our test set\n",
    "test_survey = np.array([\n",
    "  [1, 1, 1, 0, 1],\n",
    "  [0, 0, 0, 1, 0],\n",
    "  [0, 0, 1, 0, 0],\n",
    "  [1, 0, 1, 0, 1]\n",
    "])\n",
    "\n",
    "features_test = test_survey[:, 0:4]\n",
    "labels_test = test_survey[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKQca9MxDgjQ"
   },
   "source": [
    "# Step 2. Build and train an AI classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6klW7bgFjCa"
   },
   "source": [
    "Next, we need to build a neural network and train it to help us make predictions. We're going to import a library called SKLearn and use its algorithms to build a simple multi-layer perceptron neural network or MLP. \n",
    "\n",
    "As a refresher, this neural network has an input layer for features, some number of hidden layers to learn representations, and a final output layer to make a prediction. The hidden layers find relationships between the features that help it make accurate predictions.\n",
    "\n",
    "There are a lot of parameters we can play with here! But we'll start with something simple: four input features, one hidden layer (with four neurons, the same size as our input), and two outputs (YES, happiness, or NO, unhappiness). SKLearn actually takes care of counting the size of our input and output automatically, so we only have to specify the hidden layers in the code. \n",
    "\n",
    "Over the span of one epoch of training this neural network, the hidden layer will pick up on patterns in the input features, and pass a prediction to one of two output neurons. The code calls this an “iteration” because an iteration and an epoch are the same thing in the algorithm we’re using. Over multiple epochs of the same training dataset, the neural network’s predictions should keep getting better! So we’ll just go with 1000 epochs for now. \n",
    "\n",
    "\n",
    "**Step 2.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVzQqjoprfAB"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Define the model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(4,),  # CHANGEME\n",
    "                    activation='tanh',        # ADVANCED_CHANGEME\n",
    "                    max_iter=1000,            # CHANGEME\n",
    "                    random_state=1   \n",
    "                   )\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7g8uQWiFdsC"
   },
   "source": [
    "Now, we can test our AI classifier on the original training data to see how well it captured that information, and on the testing data we set aside to see how good its predictions are.\n",
    "\n",
    "**Step 2.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFyuDNzCFXyZ"
   },
   "outputs": [],
   "source": [
    "print(\"Training set score: %f\" % mlp.score(features_train, labels_train))\n",
    "print(\"Testing set score: %f\" % mlp.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dvr79nxCF6hY"
   },
   "source": [
    "# Step 3. Make predictions\n",
    "\n",
    "Well, this project is almost over! Everything was easy to do, and the performance looks perfect. We can just put in some pet features and let it help with a big life decision! AI really is awesome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mYm4bONxMGM"
   },
   "source": [
    "Should I get a cat? Let me try some cats, the first is not Energetic (lazy), Cuddly, Soft, and Quiet pet? We can encode that as:\n",
    "\n",
    "*   Not Energetic = 0\n",
    "*   Cuddly = 1\n",
    "*   Soft = 1\n",
    "*   Quiet = 1\n",
    "\n",
    "So our features are ```[[0, 1, 1, 1]]```\n",
    "\n",
    "The others are also lazy:\n",
    "\n",
    "```[[0, 0, 1, 1]]```\n",
    "```[[0, 1, 1, 0]]```\n",
    "```[[0, 1, 0, 1]]```\n",
    "\n",
    "**Step 3.1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBvQOnfNxGAJ"
   },
   "outputs": [],
   "source": [
    "# Energetic, Cuddly, Soft, Quiet\n",
    "features = [[0, 1, 1, 1]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "\n",
    "features = [[0, 0, 1, 1]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "features = [[0, 1, 1, 0]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "features = [[0, 1, 0, 1]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bh0B3BaCxPmD"
   },
   "source": [
    "Interesting, let's try another one. Should I get a dog that is Energetic, not Cuddly, not Soft, and not Quiet?\n",
    "\n",
    "*   Energetic = 1\n",
    "*   Not Cuddly = 0\n",
    "*   Not Soft = 0\n",
    "*   Not Quiet = 0\n",
    "\n",
    "So our features are ```[[1, 0, 0, 0]]```\n",
    "\n",
    "Let me try more dogs:\n",
    "\n",
    "```[[1, 0, 0, 0]]```\n",
    "```[[1, 1, 0, 0]]```\n",
    "```[[1, 0, 1, 0]]```\n",
    "```[[1, 0, 0, 1]]```\n",
    "\n",
    "**Step 3.2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsmdXpmXxRgx"
   },
   "outputs": [],
   "source": [
    "# Energetic, Cuddly, Soft, Quiet\n",
    "features = [[1, 0, 0, 0]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "\n",
    "features = [[1, 1, 0, 0]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "\n",
    "features = [[1, 0, 1, 0]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")\n",
    "\n",
    "features = [[1, 0, 0, 1]]    # CHANGEME\n",
    "print(\"Yes!\" if mlp.predict(features)[0] else \"No!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPIuifGrKLoq"
   },
   "source": [
    "# Step 4.  Data analysis\n",
    "\n",
    "So, obviously, AI doesn’t have a grudge against cats. We collected the survey data and built the AI, so if something went wrong and introduced an anti-cat bias… it’s on us, and we can audit our AI to figure out what it is.\n",
    "\n",
    "Particularly in problems where we have a small set of features, we can actually visualize all the correlations between those features. To do this, we'll use some bar plot and database libraries:\n",
    "```\n",
    "matplotlib, seaborn, pandas\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R6-81MHKxa1m"
   },
   "source": [
    "What’s weird is that the model’s predictions don’t make sense, despite the high performance. Specifically, there seems to be a bias towards dogs. Are dog owners generally happier than cat owners?? \n",
    "\n",
    "Earlier, we decided to just pool all the survey results together, but now we'll split them apart. We can create plots that compare the percentage of dog owners surveyed who are happy, the percentage of cat owners surveyed who are happy, and the percentage of all the people surveyed who are happy with their pets (no matter what kind). \n",
    "\n",
    "To do this, we just need to compute the number of happy dog owners divided by the total number of dog owners, the number of happy cat owners divided by the total number of cat owners, and the number of happy pet owners divided by the total number of people we surveyed.\n",
    "\n",
    "**Step 4.1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVrXT-R6xris"
   },
   "outputs": [],
   "source": [
    "# Split the survey up into the cat and dog entries\n",
    "dog_survey = survey[:-4]  \n",
    "cat_survey = survey[-4:]\n",
    "\n",
    "# Import plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(1, 4)\n",
    "\n",
    "# Add up the number of survey participants who are happy and\n",
    "# divide by the total number of participants of each type\n",
    "happy_dog = 100*np.sum(dog_survey,axis=0)[-1]/dog_survey.shape[0]\n",
    "happy_cat = 100*np.sum(cat_survey,axis=0)[-1]/cat_survey.shape[0]\n",
    "happy = 100*np.sum(survey, axis=0)[-1]/survey.shape[0]\n",
    "\n",
    "# Make a bar chart\n",
    "pt, pd, pc = plt.bar(ind, (happy, happy_dog, happy_cat))\n",
    "\n",
    "# Assign colors to bars\n",
    "pt.set_facecolor('b')\n",
    "pd.set_facecolor('r')\n",
    "pc.set_facecolor('g')\n",
    "\n",
    "# Put labels on everything\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(['Happy', 'Happy | Dog', 'Happy | Cat'])\n",
    "ax.set_ylim([0, 100])\n",
    "ax.set_ylabel('Percent')\n",
    "_ = ax.set_title('Which Pet?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpZtLy5hxwcy"
   },
   "source": [
    "Well, that's confusing. According to our survey results, 100% of cat owners are happy and the dog owners are kind of split. But when we put in the features for a cat, our AI classifier usually says it won’t make the owner happy. What's wrong?\n",
    "\n",
    "Let's look at a different dimension of our data and plot the total number of survey responses from dog owners and cat owners.\n",
    "\n",
    "\n",
    "**Step 4.2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeNYRBaEy5Ao"
   },
   "outputs": [],
   "source": [
    "# Import library to make plots\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ind = np.arange(1, 3)\n",
    "\n",
    "# Count the number of responses from dog vs cat owners\n",
    "dog = dog_survey.shape[0]\n",
    "cat = cat_survey.shape[0]\n",
    "\n",
    "# Make a bar chart\n",
    "pd, pc = plt.bar(ind, (dog, cat))\n",
    "\n",
    "# Assign colors to bars\n",
    "pd.set_facecolor('r')\n",
    "pc.set_facecolor('g')\n",
    "\n",
    "# Put labels on everything\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels(['# Dog', '# Cat'])\n",
    "ax.set_ylim([0, 25])\n",
    "ax.set_ylabel('Number')\n",
    "_ = ax.set_title('Which Pet?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UyqP_yoQMd8M"
   },
   "source": [
    "Yikes! A lot of people who responded to our survey owned dogs. So our **first mistake** is that the dataset we used doesn’t actually have the same distributions as the real world. Instead of collecting the true frequencies of each feature from a large random group of pet owners, we accidentally sampled from a dog-biased set. \n",
    "\n",
    "That’s definitely something that should be fixed… but it still doesn’t answer why the model seems so biased against cats. Both cats and dogs can be energetic, cuddly, quiet, and soft. That’s why we chose those features, they seemed like they’d be common for both pets. \n",
    "\n",
    "But we can test this. We'll plot how often each feature is true for both dogs and cats by dividing the number of times each feature is true for each animal by the total number of survey responses we have for each animal.  \n",
    "\n",
    "\n",
    "**Step 4.3** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jV2l9WMBMaZD"
   },
   "outputs": [],
   "source": [
    "# Import libraries to build a plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ind = np.arange(0, 4)\n",
    "\n",
    "# Count number of dog and cat surveys\n",
    "total_dog = dog_survey.shape[0]\n",
    "total_cat = cat_survey.shape[0]\n",
    "\n",
    "# Count how often each feature is true divided by how many dogs and cats we have\n",
    "cat_probabilities = 100*cat_survey[:,:4].sum(axis=0)/total_cat\n",
    "dog_probabilities = 100*dog_survey[:,:4].sum(axis=0)/total_dog\n",
    "\n",
    "# Input the data into a bar plot\n",
    "data = {'Feature':[], 'Animal':[], 'Probability':[]}\n",
    "for feature in range(4):\n",
    "  data['Feature'].append(feature)\n",
    "  data['Animal'].append('dog')\n",
    "  data['Probability'].append(dog_probabilities[feature])\n",
    "\n",
    "  data['Feature'].append(feature)\n",
    "  data['Animal'].append('cat')\n",
    "  data['Probability'].append(cat_probabilities[feature])\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "_ = sns.barplot(x='Feature', y='Probability', hue='Animal', data=df, ax=ax)\n",
    "\n",
    "# Label everything\n",
    "ax.set_xticklabels(['Energetic', 'Cuddly', 'Soft', 'Quiet'])\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 24)\n",
    "_ = fig.suptitle('How often is each pet ____?', fontsize=20)\n",
    "_ = plt.ylabel('Probability', fontsize=18)\n",
    "_ = ax.set_ylim([0, 100])\n",
    "_ = plt.xlabel('Features', fontsize=18)\n",
    "_ = plt.legend(loc='best', prop={'size':18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTHWwKIoUeGK"
   },
   "source": [
    "So it looks like there are lots of different types of dogs in our dataset, but none of the cats are energetic. So this is a **correlated feature**, which is a feature that is (unintentionally) correlated to a specific prediction or hidden category. In this case, knowing if something is energetic is a cheat for knowing it’s a dog even though we didn’t tell the model about dogs. \n",
    "\n",
    "My model might have then learned that if a pet is energetic, it makes owners happy, just because there was no data to tell it otherwise. We can see if this weird correlation is real by plotting energetic vs owner happiness. \n",
    "\n",
    "\n",
    "**Step 4.4** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXagWEITQs7X"
   },
   "outputs": [],
   "source": [
    "# Import libraries for a plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ind = np.arange(0, 4)\n",
    "\n",
    "# Count how often each animal is relaxed or energetic\n",
    "energetic = [0,0]\n",
    "energetic_count = 0\n",
    "relaxed = [0,0]\n",
    "relaxed_count = 0\n",
    "\n",
    "for entry in survey:\n",
    "  if entry[0] == 0:\n",
    "    relaxed[entry[-1]] += 1\n",
    "    relaxed_count += 1\n",
    "  else:\n",
    "    energetic[entry[-1]] += 1\n",
    "    energetic_count += 1\n",
    "\n",
    "# Put the values in a a database\n",
    "data = {'Feature':[], 'Happy':[], 'Probability':[]}\n",
    "data[\"Feature\"].append(\"Energetic\")\n",
    "data[\"Happy\"].append(\"No\")\n",
    "data[\"Probability\"].append(100*energetic[0]/energetic_count)\n",
    "\n",
    "data[\"Feature\"].append(\"Energetic\")\n",
    "data[\"Happy\"].append(\"Yes\")\n",
    "data[\"Probability\"].append(100*energetic[1]/energetic_count)\n",
    "\n",
    "data[\"Feature\"].append(\"walk\")\n",
    "data[\"Happy\"].append(\"No\")\n",
    "data[\"Probability\"].append(100*relaxed[0]/relaxed_count)\n",
    "\n",
    "data[\"Feature\"].append(\"walk\")\n",
    "data[\"Happy\"].append(\"Yes\")\n",
    "data[\"Probability\"].append(100*relaxed[1]/relaxed_count)\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "# Plot bar plot and put labels on everything\n",
    "_ = sns.barplot(x='Feature', y='Probability', hue='Happy', data=df, ax=ax)\n",
    "ax.set_xticklabels(['Energetic', 'Relaxed'])\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 24)\n",
    "_ = fig.suptitle('What makes people happy?', fontsize=20)\n",
    "_ = plt.ylabel('Probability', fontsize=18)\n",
    "_ = ax.set_ylim([0, 100])\n",
    "_ = plt.xlabel('Features', fontsize=18)\n",
    "_ = plt.legend(loc='best', prop={'size':18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKH-IV3tCRI3"
   },
   "source": [
    "In our data, if a pet is energetic, a person is very likely to be happy with it... no matter what other features are true. But if the pet isn’t energetic, it’s a mixed bag of happiness. \n",
    "\n",
    "So this is definitely our **second mistake**: the data had a correlated feature, so our AI found patterns that we didn’t want. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>**Few question to think after running the code:**</h1>\n",
    "\n",
    "What are your thoughts about the performance of the classifier? What does that suggest?\n",
    "\n",
    "What statistical problems can you identify?\n",
    "\n",
    "How to fix this bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Bias Lab: Crash Course AI#19",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
